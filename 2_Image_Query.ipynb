{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Building an Image Search Engine - Image Query**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image search engine project built a prototype to enable image query. The guided project has two parts. The first part focus on building the image encoding system and the second part focus on building the image query system.\n",
    "\n",
    "This application has many business use cases such as:\n",
    "\n",
    "1.  Enable customers to look for similar apparels, furniture, auto parts etc.\n",
    "2.  Help image application to eliminate near duplicated images.\n",
    "3.  Enable image to be used as feature embedding for modeling task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this notebook you will be able to:\n",
    "\n",
    "*   Import the embeddings dataset from previous notebook\n",
    "*   Generate embeddings for a query image\n",
    "*   Search the embeddings dataset for closest match for the given query image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhlZtNR4GW25"
   },
   "source": [
    "## Setup Runtime\n",
    "\n",
    "*   we recommand to use anaconda to manage your runtime.\n",
    "*   install the dependencies into your runtime.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System requirements:\n",
    "\n",
    "1.  Stable internet access\n",
    "2.  TensorFlow 2.x\n",
    "3.  Jupyter notebook\n",
    "4.  2GB storage if choose local file system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S-3kCzhML53_"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "import zipfile\n",
    "\n",
    "import PIL\n",
    "import PIL.Image as Image\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.xception import Xception\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import skillsnetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PfeK7C3Gmvj"
   },
   "source": [
    "##  Download Image Dataset\n",
    "\n",
    "*Note* : If you have downloaded the dataset as part of the previous notebook, please skip this step.\n",
    "\n",
    "For this prototype we will use a clothing dataset of tshirts/apparel created by [Alexey Grigorev](https://github.com/alexeygrigorev). A fork of the dataset can be found [here](https://github.com/CODAIT/clothing-dataset) on IBM CODAIT's GitHub.\n",
    "\n",
    "*   Click [the link](https://github.com/CODAIT/clothing-dataset) to download the data manually.\n",
    "*   Save the downloaded dataset to your local file system.\n",
    "\n",
    "Alternatively you can use the `wget` command below to download the dataset within the notebook kernel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "!git clone https://github.com/CODAIT/clothing-dataset.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWa7kiYOPOIj"
   },
   "source": [
    "##  Load The Image Encodings and Image Disctionary\n",
    "\n",
    "Now we load the image encodings/embeddings we generated in the previous notebook into memory. In case you haven't generated the embeddings as part of the previous notebook, please use this link or clone the github repo for this guided project to find the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Download the embeddings if the previous notebook wasn't executed fully\n",
    "# UNCOMMENT THE CELL BELOW\n",
    "# await skillsnetwork.prepare(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX0W3UEN/cloth-vgg16-500dim-encodings.npy.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7cRae2IqPd2h"
   },
   "outputs": [],
   "source": [
    "# load saved encoding\n",
    "\n",
    "image_encodings = np.load('cloth-vgg16-500dim-encodings.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuAr-aLPQPPv"
   },
   "source": [
    "Next, we load the image dictionary that contains the mapping from the image name to the underlying file path on disc for retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Download the mapping file if the previous notebook wasn't executed fully\n",
    "# !wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-GPXX0W3UEN/image_dictionary.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "k8KCJW2QQQTu",
    "outputId": "fc7cfb76-5517-4d8f-a2cc-10706b236771"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('image_dictionary.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UuQmq4B3Pmpz"
   },
   "source": [
    "##  Query Similar Apparel\n",
    "\n",
    "We are finally ready to query the dataset given a sample image.\n",
    "\n",
    "Step 1: First we pick a random image (`index i`) and then generate the embedding for that image. Since we are picking an image from the dataset, we can also retrieve the embedding for that image from our dataset.\n",
    "\n",
    "Step 2: Use a similarity metric to measure distance to all embeddings and get the closest ones. In our example we use the `cosine` similarity distance metric.\n",
    "\n",
    "Step 3: Retrieve the underlying images for the closest matching embeddings and visualize them to show as output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "aU_Cw_pkQESg",
    "outputId": "1af843ed-9418-42e2-ed92-2ae2f79606ee"
   },
   "outputs": [],
   "source": [
    "# example 1, 2, 9, 100, 114, 1200, 1500, 5000\n",
    "\n",
    "# Step 1\n",
    "# Change `i` to query a different image and try out other images\n",
    "i = 455\n",
    "\n",
    "print('> Query Image:')\n",
    "display(PIL.Image.open(df.iloc[i]['full_path_file_name']))\n",
    "# inverse indexing design\n",
    "foo = np.zeros(image_encodings.shape[0])\n",
    "\n",
    "\n",
    "# Step 2\n",
    "for j in range(image_encodings.shape[1]):\n",
    "    encodings = image_encodings[:,j,:]\n",
    "    foo += np.dot(encodings, encodings[i].reshape(-1,1)).ravel()\n",
    "result = np.argsort(foo)\n",
    "\n",
    "# Step 3\n",
    "print('> Top 3 Similar Images:')\n",
    "for j in [-2,-3,-4,-5]:\n",
    "    print(foo[result[j]])\n",
    "    display(PIL.Image.open(df.iloc[result[j]]['full_path_file_name']))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Image_Search_Engine_Part_B.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
