{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Building an Image Search Engine - Image Encoding**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This guided project will help you build an image querying prototype. The project is split into two parts. The first part focuses on building the image encoding system and the second part focuses on building the image query system.\n",
    "\n",
    "This application has many business use cases such as:\n",
    "\n",
    "1.  Enabling customers to look for similar apparel, furniture, auto parts etc.\n",
    "2.  Help eliminate near duplicate images from databases or catalogues.\n",
    "3.  Enable image to be used as feature embedding for modeling tasks.\n",
    "4.  Build image based recommendation systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "After completing this notebook you will be able to:\n",
    "\n",
    "*   Setup an Image Encoding service that accepts input images and produces embeddings\n",
    "*   Explore techniques for generating embeddings\n",
    "*   Generate the embeddings for the dataset and save it on disc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhlZtNR4GW25"
   },
   "source": [
    "## Setup Runtime\n",
    "\n",
    "*   we recommend the use of anaconda to manage the runtime.\n",
    "*   install the dependencies within the Anaconda runtime.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System requirements:\n",
    "\n",
    "1.  Stable internet access (to download the dataset)\n",
    "2.  TensorFlow 2.x\n",
    "3.  Jupyter notebook\n",
    "4.  2GB of storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0hNU3yTnD9mJ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "import zipfile\n",
    "\n",
    "import PIL\n",
    "import PIL.Image as Image\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.xception import Xception\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PfeK7C3Gmvj"
   },
   "source": [
    "- ## Download Image Dataset\n",
    "\n",
    "For this prototype we will use a clothing dataset of tshirts/apparel created by [Alexey Grigorev](https://github.com/alexeygrigorev). A fork of the dataset can be found [here](https://github.com/CODAIT/clothing-dataset) on IBM CODAIT's GitHub.\n",
    "\n",
    "*   Click [the link](https://github.com/CODAIT/clothing-dataset) to download the data manually.\n",
    "*   Save the downloaded dataset to your local file system.\n",
    "\n",
    "Alternatively you can use the `git clone` command below to download the dataset within the notebook kernel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "!git clone https://github.com/CODAIT/clothing-dataset.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIQgGWa4HmIN"
   },
   "source": [
    "## Preprocessing the Dataset\n",
    "\n",
    "We will now build a pandas dataframe that contains image file paths of valid images. We will discard invalid images.\n",
    "To do this, we will first try to open the images using the `PIL.Image.open()` method and drop the image if the method failed to open the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "id": "ZqOBvXF2ISCP",
    "outputId": "9f53ba1e-62b8-4c86-fb7c-b7ce611f33f0"
   },
   "outputs": [],
   "source": [
    "from os import walk \n",
    "\n",
    "path = 'clothing-dataset/images/'\n",
    "filename_list = []\n",
    "\n",
    "# collect all files\n",
    "for (dirpath, dirnames, filenames) in walk(path):\n",
    "    filename_list.extend(filenames)\n",
    "    break\n",
    "\n",
    "# validate images\n",
    "filename_list_verified = []\n",
    "for index, fname in enumerate(filename_list):\n",
    "    try:\n",
    "        im = Image.open(path + fname)\n",
    "        filename_list_verified.append(fname)\n",
    "    except Exception as e:\n",
    "        print('invalid image index:', index)\n",
    "\n",
    "df = pd.DataFrame(data={'filename': filename_list_verified})\n",
    "df['full_path_file_name'] = path + df['filename']\n",
    "df['class'] = \"1\"\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have a dataframe of all valid images and their full paths on the disc, we store that as a CSV file for quick access later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.to_csv(df, 'image_dictionary.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsEGFwzzIapF"
   },
   "source": [
    "##  Implement The LSH TF Layer\n",
    "\n",
    "Local Sensitive Hashing is a popular hashing technique which we will use in our prototype to generate embeddings for the images.\n",
    "To perform that, we first need to create a custom `Layer` object in Keras/tensorflow.\n",
    "We can achieve that by doing the following steps:\n",
    "\n",
    "*   Implement the custom TF layer by subclass the `tf.keras.layers.Layer` class\n",
    "*   Implement the `HyperPlane Hashing` in the `call()` method of `layer` class\n",
    "\n",
    "For more details about Local Sensitive Hashing and HyperPlane Hashing please follow this [link](https://web.stanford.edu/class/cs246/slides/03-lsh.pdf?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkQuickLabsIBMGPXX0W3UEN35891832-2022-01-01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EdFvrjzdJgDK"
   },
   "outputs": [],
   "source": [
    "# perform hyper plan hashing\n",
    "# the output is intended for LSH algorithm\n",
    "class HyperPlaneHashingLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    # perform input independent initialization\n",
    "    # initialize the random_seed\n",
    "    def __init__(self, n, random_seed=628):\n",
    "        \"\"\"\n",
    "        @param::random_seed: the random seed used to generate the hyperplan\n",
    "        @param::n: the number of hashing performed\n",
    "        return none\n",
    "        \"\"\"\n",
    "        #super(tf.keras.layers.Layer, self).__init__()\n",
    "        super().__init__()\n",
    "        self.random_seed = random_seed\n",
    "        self.n = n\n",
    "        self.hyperplanes = []\n",
    "\n",
    "    # initialize the hyperplane matrix based on the input size \n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "        @param::input_shape: the shape of input tensor\n",
    "        return none\n",
    "        \"\"\"\n",
    "        if len(input_shape) <= 3:\n",
    "          raise Exception('> input dimension need to greater than 3.')\n",
    "        tf.random.set_seed(self.random_seed)\n",
    "        # each column represent a hashing vector\n",
    "        self.hyperplanes = K.random_uniform((input_shape[-1], self.n),  \n",
    "                                              minval=-1., \n",
    "                                              maxval=1., \n",
    "                                              seed=self.random_seed)\n",
    "\n",
    "    # return the hyperplane hashing result\n",
    "    def call(self,input):\n",
    "        \"\"\"\n",
    "        @param::input: the input tensor\n",
    "        return the hyperplane hashed representation of each input data points\n",
    "        \"\"\"\n",
    "        # scaled = K.mean(input, axis=0) - input\n",
    "        scaled = tf.reshape(input,(-1,input.shape[-2]*input.shape[-3],input.shape[-1]))\n",
    "        # print(scaled.shape)\n",
    "        hash_val = tf.matmul(scaled, self.hyperplanes)\n",
    "        hash_result = (hash_val) > 0\n",
    "        return K.cast(hash_result, tf.int32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AfkNU33vJvW0"
   },
   "source": [
    "##  Build Encoding Network\n",
    "\n",
    "*   Use the pretrained VGG16 network as the feature extraction network. More detail about [pretrained models](https://keras.io/api/applications/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkQuickLabsIBMGPXX0W3UEN35891832-2022-01-01) in keras.\n",
    "*   Use the LSH layer built in the previous section to reduce the dimensionality of the embeddings output by the pretrained network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2z2zUBxgK98W",
    "outputId": "cb46a86d-429c-4ec7-a873-b6a51ab0e451"
   },
   "outputs": [],
   "source": [
    "# VGG16\n",
    "# Preprocessing expected input: 0-255 float32\n",
    "i = tf.keras.layers.Input([None, None, 3], dtype = tf.float32)\n",
    "x = tf.keras.applications.vgg16.preprocess_input(i) \n",
    "x = VGG16(include_top=False, weights='imagenet', input_shape=(224,224,3))(x)\n",
    "#x = tf.keras.layers.MaxPool2D()(x)\n",
    "#x = tf.keras.layers.MaxPool2D()(x)\n",
    "#x = tf.keras.layers.Flatten()(x)\n",
    "x = HyperPlaneHashingLayer(500)(x)\n",
    "model = tf.keras.Model(inputs=[i], outputs=[x])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMhyUTFULNaA"
   },
   "source": [
    "##  Encode the Images\n",
    "\n",
    "We now encode all the images in the dataset and store the embeddings on disc for retrieval tasks later in the pipeline.\n",
    "Since the image dataset is large, it might take a long time to generat the embeddings for all the images. Here we show how to generate embeddings for a subset of the images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image subset\n",
    "df_subset = df[0:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7d3qF5KmLGPy",
    "outputId": "9366f545-f44a-4448-9a91-4af86b106629"
   },
   "outputs": [],
   "source": [
    "# init the image generator\n",
    "image_datagen = ImageDataGenerator()\n",
    "image_generator = image_datagen.flow_from_dataframe(dataframe=df_subset, \n",
    "                                                    x_col=\"full_path_file_name\",\n",
    "                                                    y_col=\"class\", \n",
    "                                                    color_mode='rgb',\n",
    "                                                    target_size=(224,224),\n",
    "                                                    shuffle=False,\n",
    "                                                    validate_filenames=True,\n",
    "                                                    batch_size=128)\n",
    "\n",
    "# feed forward the network to generate the encoding\n",
    "image_encodings = model.predict(image_generator)\n",
    "print(image_encodings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out a single enconding/embedding\n",
    "image_encodings[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vislualize a single encoding/embedding\n",
    "plt.imshow(image_encodings[0,:,:])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Image_Search_Engine_Part_A.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
